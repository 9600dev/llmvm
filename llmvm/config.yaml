# install in ~/.config/llmvm/config.yaml
# or set LLMVM_CONFIG environment variable to this file
server_host: '0.0.0.0'
server_port: 8011
profiling: false
profiling_file: '~/.local/share/llmvm/profiling_trace.log'
executor_trace: '~/.local/share/llmvm/executor_trace.log'
firefox_profile: '~/.mozilla/firefox/cp6sgb0s.selenium'
firefox_download_directory: '~/.local/share/llmvm/download'
firefox_cookies: '~/.local/share/llmvm/cookies.txt'
firefox_headless: true
chrome_headless: true
chrome_cookies: '~/.local/share/llmvm/cookies.txt'
smtp_server: 'localhost'
smtp_port: 1025
smtp_username: 'hello@hello.com'
smtp_password: 'password'
cache_directory: '~/.local/share/llmvm/cache'
cdn_directory: '~/.local/share/llmvm/cdn'
log_directory: '~/.local/share/llmvm/logs'
vector_store_index_directory: '~/.local/share/llmvm/faiss'
vector_store_embedding_model: 'all-MiniLM-L6-v2' # 'BAAI/bge-base-en'
vector_store_chunk_size: 500
openai_api_base: 'https://api.openai.com/v1'
openai_model: 'gpt-4o'
openai_max_tokens: 128000
anthropic_api_base: 'https://api.anthropic.com'
anthropic_model: 'claude-3-5-sonnet-20240620'
anthropic_max_tokens: 200000
local_api_base: 'http://localhost:8000/v1'
local_model: 'llongorca.gguf'
local_model_max_tokens: 16385
executor: 'openai'  # openai, anthropic, local
helper_functions:
  - llmvm.server.bcl.BCL.datetime
  - llmvm.server.tools.webhelpers.WebHelpers.search_linkedin_profile
  - llmvm.server.tools.webhelpers.WebHelpers.get_linkedin_profile
  - llmvm.server.tools.edgar.EdgarHelpers.get_report
  - llmvm.server.tools.market.MarketHelpers.get_stock_price
  - llmvm.server.tools.market.MarketHelpers.get_current_market_capitalization
  - llmvm.server.tools.market.MarketHelpers.get_stock_volatility
  - llmvm.server.tools.market.MarketHelpers.get_stock_price_history
  - llmvm.server.bcl.BCL.sample_normal
  - llmvm.server.bcl.BCL.sample_binomial
  - llmvm.server.bcl.BCL.sample_lognormal
  - llmvm.server.bcl.BCL.sample_list
  - llmvm.server.bcl.BCL.generate_graph_image
