# install in ~/.config/llmvm/config.yaml
# or set LLMVM_CONFIG environment variable to this file
server_host: '0.0.0.0'
server_port: 8011
profiling: false
profiling_file: '~/.local/share/llmvm/profiling_trace.log'
executor_trace: '~/.local/share/llmvm/executor.trace'
chromium_headless: true
chromium_cookies: '~/.local/share/llmvm/cookies.txt'
cache_directory: '~/.local/share/llmvm/cache'
cdn_directory: '~/.local/share/llmvm/cdn'
log_directory: '~/.local/share/llmvm/logs'
memory_directory: '~/.local/share/llmvm/memory'
vector_store_index_directory: '~/.local/share/llmvm/faiss'
vector_store_embedding_model: 'all-MiniLM-L6-v2' # 'BAAI/bge-base-en'
vector_store_chunk_size: 500
openai_api_base: 'https://api.openai.com/v1'
anthropic_api_base: 'https://api.anthropic.com'
deepseek_api_base: 'https://api.deepseek.com/v1'
gemini_api_base: 'https://generativelanguage.googleapis.com/v1beta'
bedrock_api_base: 'us-east-1'
default_openai_model: 'gpt-4o'
default_anthropic_model: 'claude-3-7-sonnet-20250219'
default_gemini_model: 'gemini-2.0-flash-exp'
default_deepseek_model: 'deepseek-chat'
default_bedrock_model: 'amazon.nova-pro-v1:0'
executor: 'anthropic'  # openai, anthropic, gemini, deepseek, bedrock
override_max_input_tokens: None
override_max_output_tokens: None
helper_functions:
  - llmvm.server.tools.webhelpers.WebHelpers.search_linkedin_profile
  - llmvm.server.tools.webhelpers.WebHelpers.get_linkedin_profile
  - llmvm.server.tools.webhelpers.WebHelpers.get_hackernews_latest
  - llmvm.server.tools.edgar.EdgarHelpers.get_report
  - llmvm.server.tools.market.MarketHelpers.get_stock_price
  - llmvm.server.tools.market.MarketHelpers.get_current_market_capitalization
  - llmvm.server.tools.market.MarketHelpers.get_stock_volatility
  - llmvm.server.tools.market.MarketHelpers.get_stock_price_history
  - llmvm.server.tools.market.MarketHelpers.get_stock_analysis
  - llmvm.server.bcl.BCL.datetime
  - llmvm.server.bcl.BCL.sample_normal
  - llmvm.server.bcl.BCL.sample_binomial
  - llmvm.server.bcl.BCL.sample_lognormal
  - llmvm.server.bcl.BCL.sample_list
  - llmvm.server.bcl.BCL.generate_graph_image
  - llmvm.server.bcl.BCL.matplotlib_to_image
  - llmvm.server.bcl.BCL.get_source_code_structure_summary
  - llmvm.server.bcl.BCL.get_source_code
  - llmvm.server.bcl.BCL.find_all_references_to_method
  - llmvm.server.bcl.BCL.get_weather
  - llmvm.server.bcl.BCL.address_lat_lon
  - llmvm.server.bcl.BCL.get_currency_rates
  - llmvm.server.bcl.BCL.get_gold_silver_price_in_usd
  - llmvm.server.bcl.BCL.get_bitcoin_prices_in_usd
  - llmvm.server.bcl.BCL.get_central_bank_rates
  - llmvm.server.bcl.BCL.get_tvshow_ratings_and_details
  - llmvm.server.bcl.BCL.search_and_replace
  - llmvm.server.bcl.BCL.find
  - llmvm.server.tools.browser.Browser
  - llmvm.server.tools.macos_chrome_browser.MacOSChromeBrowser

# optional client color Python rich syntax
client_stream_token_color: 'bright_black'
client_stream_thinking_token_color: 'cyan'
client_role_color: 'bold cyan'
client_repl_color: 'ansibrightcyan'
