[system_message]
You are a helpful compiler.

[user_message]
Your job is to take the previous {{user_colon_token}} and {{assistant_colon_token}} messages that the User initiated, and "compile them" into Python code that uses the helpers and special helpers defined in the first message and system prompt.

Your workflow looks like this:

1) Figure out from the {{user_colon_token}} and {{assistant_colon_token}} thread what can be "genericized" and "optimized". Given there are many ways to genericize, particularly on parameters to the program, consider making the defaults aligned to the data in the previous message thread, but parameterized so that a caller can specialize or change the data if needed.

2) Then generate just Python code that can basically replicate the actions and workflow that was done throughout the {{user_colon_token}} and {{assistant_colon_token}} message exchange. The Python code can use all the special helpers and added helpers defined and presented in the first prompt, but should try to avoid using llm_call and llmvm_call as they are expensive calls back to the llm and we want to specialize using code, rather than rely on the LLM.

Given an LLM can deal with a lot of ambiguity and probabilistic interpretations of data, and code is usually more "specialized", you should consider adding "guards" in the code that will raise an Exception if a specialization or assumption you're making fails as a result of the data being different. An example of this would be specializing for the extraction of data from a web page knowing that the structure of the web page may occasionally change if they redeploy it. Use these "guards" liberally, because if they are hit, I will reinvoke you to generate a new branch of code from that guard point that will specialize against the new data. You can think of this guard trick as sort of like a JIT compiler that specializes code for a given set of types (type guards), but in this case, we're specializing for a shape of data that we are observing, hoping that it either never changes, or doesn't change often. Use guards liberally for this case. If you think the data will be different often, you can call back into the LLM to deal with this rather than trying to write code specializations with guards.

Because guard's are special, we have added a special helper for them:

def guard(assertion: Callable[[], bool], error_message: str, bind_prompt: Optional[str] = None) -> Any. assertion is the test condition of the data that must be true in order to proceed, error_message is for the exception that will be raised if the guard returns false or fails, and bind_prompt is a prompt that might be given to an LLM to try and reshape the expr data to satisfy the condition.

Let's walk through an example of this, starting with looking at a {{user_colon_token}}/{{assistant_colon_token}} message exchange:

{{user_colon_token}} what is the current price of NVDA in AUD?

{{assistant_colon_token}}

Let me get that for you:

<helpers>
now = BCL.datetime("now", "America/Vancouver")
nvda_price_usd = MarketHelpers.get_stock_price("NVDA", now)

# 2. Get USD to AUD exchange rates
usd_rates = BCL.get_currency_rates("USD")
result([nvda_price_usd, usd_rates])
</helpers>

<helpers_result>
137.3800048828125
Currency rates for USD:\n{'USD': 1, 'AED': 3.6725, 'AFN': 69.435971, 'ALL': 86.413054, 'AMD': 384.571385, 'ANG': 1.79, 'AUD': 1.540697, 'XCD': 2.7, 'XCG': 1.79, 'XDR': 0.729147, 'XOF': 573.747391, 'XPF': 104.37639, 'YER': 243.635852, 'ZAR': 17.863842, 'ZMW': 26.681136, 'ZWL': 6.9213}
</helpers_result>

The current price of NVIDIA (NVDA) is $137.38 USD and the current exchange rate is 1 USD = 1.540697.

<helpers>
usd_to_aud = 1.540697
nvda_price_aud = coerce(nvda_price_usd,float) * usd_to_aud
result(f"""The price of NVDA in AUD is ${nvda_price_aud:.2f}""")
</helpers_result>

The current price of NVIDIA (NVDA) is $137.38 USD, which is approximately $211.66 AUD at the current exchange rate (1 USD = 1.54 AUD).

Okay, for (1) it seems that genericizing this would mean that it should work for any stock symbol, not just NVDA. It's also clear that we don't need to go back and forward to the LLM to have the LLM parse out the Python dictionary that came back from BCL.get_currency_rates("USD") because we could just write python to pull out the correct AUD conversion rate and use that directly in code.

So, this might be what (2) might look like, and what you should return as "compiled code" in a <program> xml tag. Optionally, you can add a <program_title>program name</program_title> XML tag to describe the generic title of what all the functions inside <program> actually do. If you can't figure out a generic title for the program, you can skip generating it.

<program_title>stock_currency</program_title>
<program>
def stock_to_currency(
    stock_ticker: str = llm_var_bind('stock_ticker', 'str', 'stock ticker for nasdaq/nyse', 'NVDA'),
    currency_code: str = llm_var_bind('currency_code', 'str', 'currency code for conversion from USD', 'AUD')
):
    """
    Convert a stock price into a specified currency.

    :param stock_ticker: The stock ticker to convert (default: "NVDA")
    :type stock_ticker: str
    :param currency_code: The currency code to convert to (default: "AUD")
    :type currency_code: str
    :return: str
    """
    now = BCL.datetime("now", "America/Vancouver")
    stock_price_usd = MarketHelpers.get_stock_price(stock_ticker, now)
    currency_rates_text = BCL.get_currency_rates("USD")

    # guard
    currency_rates_text = guard(lambda: currency_rates_text.strip().startswith("Currency rates for USD:"), "guard failed: Unexpected currency rates format", None)

    json_text = currency_rates_text[currency_rates_text.find('{'):].replace("'", '"')
    rates = json.loads(json_text)

    guard(lambda: currency_code in rates, f"""{currency_code} not in rates dictionary""")
    guard(lambda: isinstance(rates[currency_code], float), f"""expecting {currency_code} rate to be float""")

    usd_to_currency = float(rates[currency_code])
    stock_price_currency = stock_price_usd * usd_to_currency
    return f"""The price of {stock_ticker} in {currency_code} is ${stock_price_currency:.2f})"""
</program>

The <program> blocks that you define here to achieve goals for (1) and (2) can only have function definitions. You may create as many function definitions as you like to help componentize the code and make it more composable.

You can liberally use llm_var_bind() as a way to set method parameter defaults as it will search the locals(), globals() and previous messages for data to bind to if it is not supplied at the function call site.

Do your best effort at producing the optimized code in <program></program> tags. You are highly encouraged to perform pre-optimization analysis by generating code in <helpers> blocks to figure out how to best optimize the code you emit in <program> blocks (i.e. if you need to understand the shape of data from a helper call or something, just have a look at it by calling the helper in a <helpers> block, I'll do that processing like usual, and then after I show it to you, you generate code that uses or relies on that shape into the resulting <program> block).

If Python functions were defined in <helpers> blocks in the {{user_colon_token}} {{assistant_colon_token}} message trace, you should hoist them out and put them into the <program> block as those helpers are scope limited to the message thread itself and need to be included in the actual program to work properly.

You should try and avoid heavyweight calls back to the llm (methods like llm_call, llmvm_call are typically heavy). We are trying to offload work done via the llm to the CPU and this is part of your job of compiling and optimizing.

You can also test the functions you think you want to compile by defining and putting them into <helpers></helpers> blocks and testing them there. If they look good and test well, you can do the final copy of the functions you have written into those helpers blocks into a <program></program> block. You'll need to copy them out entirely.

Do not over genericize, or generate code that does more than the message thread asks.

The user might have added extra compilation instructions for you here: {{compile_instructions}}.

Go!