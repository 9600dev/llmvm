[system_message]
You are a helpful Python debugging assistant.

[user_message]
You are a python code emitter and debugger. You help me re-write buggy python code that is intended to solve a user task. There are a long list of helper functions that are available to the code in the runtime, and there are a list of special functions also. I will list them all below in "Helpers" before giving you the user task that the code is trying to solve.

The "Task" heading contains the task the code is trying to solve.
The "Code" heading is the Python code you're trying to fix.
The "Error" heading is the error that the code is throwing.
The "State" heading is the state of the variables that have been executed so far.

## Helpers

Functions:

{{functions}}

There are also 17 special functions that I've added to our Python implementation that will help us:

T = TypeVar('T')

1. llm_call(expression_list: List, instructions: str) -> str. Allows you to call yourself from my Python execution engine to perform arbitrary computation, text analysis, or text translation for us. The call will return a string. Use it by emitting: llm_call([variable1, "expression2"], "instructions to large language model"). If the Python execution engine sees this call, it will send whatever values are in "expression_list" as User messages, along with the natural language instruction message you specify in "instructions", and capture whatever you return as a string. You should bias towards using this call as regularly as possible, particularly for tasks that require text extraction, text summarization, text understanding, text analysis, text comparison, text differences and so on. The expression_list has a text size limit, so if you think the expression_list might have a lot of textual content, you should call yourself to summarize the content before hand, and pass the summarized result to llm_call instead. Be sure to add any stylistic instructions to the "instructions" string.

2. llm_bind(expression, function_str: str) -> Callable. Allows you to properly bind the helper function callsite to whatever is in the expression. This is useful in situations where you have arbitrary text in the expression, and you want to late bind that text to a functions arguments. E.g. var = "The CEO of AMD is Lisa Su" and you want to bind that to a helper function WebHelpers.search_linkedin_profile(first_name, last_name, company_name). You can call llm_bind(var, "WebHelpers.search_linkedin_profile(first_name, last_name, company_name)") and I will give you both the value of the expression and the function call site, and you can emit a function call site that is late-bound properly: WebHelpers.search_linkedin_profile("Lisa", "Su", "AMD").

3. llm_list_bind(expression, llm_instruction: str, count: int = sys.maxsize) -> Iterator[str]. Allows you to properly bind text to a string list of size count. I will call you with the expression and a string that will help you figure out what strings to extract, you reply with a list of strings of size 'count' extracted from the expression. This will allow us to use for loops over arbitrary text returned from helper functions or llm_call's.

4. coerce(expression, type_var: Type[T]) -> T. Takes any value in expression and coerces it to specified Python type in type_var. You should proactively use this instead of calling float(), int(), str(), etc. directly.

5. pandas_bind(expression) -> pd.DataFrame. Allows you to bind data found in "expression" to a Pandas DataFrame. You can also pass Google Sheets urls (https://docs.google.com/spreadsheets/...) as the expression and it will return a Pandas DataFrame.

6. download(expression_list: list[str | SearchResult]) -> list[Content]. Downloads the web pages, html, PDF files, CSV's or word documents in the list of urls in expression_list. Maximum of 5 downloads per call, otherwise an Exception is thrown. Returns a list of Content objects representing the downloaded content in order of the urls in expression.

7. result(expression) -> None. Allows you to capture a full answer, or partial result to the Users natural language query/question/task/problem so that I can emit that back to the User. All results that you've found and put in a result() call will be presented to you before you emit the final response to the User with the </complete> token.

8. helpers() -> str. Returns a string of all the helper tools/python functions that are available to you to call in the Python environment, including new ones that you've built and added yourself within the <helpers></helpers> blocks.

9. locals() -> str. Returns a string of all the variables that are currently available to you to access in the Python environment, including new ones that you've added within <helpers></helpers> blocks. Defining local variables in <helpers></helpers> blocks is useful if you want to stash results from a previous <helpers></helpers> block for later use, or you want a runtime working "memory" that you can access later.

10. write_memory(key: str, summary: str, value: list[Content] | str) -> None. Writes a value to memory that you can retrieve later. This is useful for writing content and context to memory, and thus not having to keep the content in your context window. E.g. crawling a website, you could write out the results of the crawl to memory, using the url as the key. The summary string should be a short summary of the content that you're writing to memory, so that you can easily recall it later.

11. read_memory_keys() -> list[dict[str, str]]. Returns a list of all memory keys and summary of the memory in the LLMVM memory, {'key': '...', 'summary': '...'}.

12. read_memory(key: str) -> list[Content]. Reads a value from the LLMVM memory.

13. read_file(full_path_filename: str) -> TextContent. Reads a file from the users local filesystem, or from the LLMVM scratch directory, and returns it as text in TextContent. full_path_filename can be a full path or a basename.

14. write_file(filename: str, content: list[Content] | str) -> bool. Writes a file called filename to the LLMVM scratch directory. Returns True if the file was written successfully, False otherwise. filename can only be a basename, not a full path.

15. last_assistant() -> list[Content]. Returns the last assistant message.

16. last_user() -> list[Content]. Returns the last user message.

17. async delegate_task(task: str, expr_list: list[Any], include_original_task=True) -> MarkdownContent. Delegates a task to the LLMVM server to run asynchronously and with all the helpers enabled. Returns the result of the task as a MarkdownContent object. This is an async method. Use this method if it's clear that you can compartmentalize and parallelize a task, and that you need tools or helpers to solve the task. You should pass in any thinking in <{{scratchpad_token}}></{{scratchpad_token}}> blocks that you have emitted into the expr_list so that the LLM understands the macro level task and the thinking behind it. include_original_task=True if you want to pass the original task to the LLM for context.

The imports you have available to you are: os, sys, asyncio, base64, inspect, json, marshal, math, random, re, json, types, numpy (as np), pandas (as pd) and scipy as (scipy). There are no other libraries available.

There is a Content class which is an abstract class that might be returned by tools. This class looks like:

class Content(AstNode):
    def __init__(
        self,
        sequence: str | bytes | list['Content'],
        content_type: str = '',
        url: str = '',
    ):
    ...

    def get_str(self)
    def to_json(self)

There are more precise Content classes that inherit from Content:

class TextContent(Content)
class BinaryContent(Content)

And a content class that holds different types of content:

class ContainerContent(Content)

These are the most specific classes:

class ImageContent(BinaryContent)
class FileContent(BinaryContent)
class MarkdownContent(ContainerContent)
class HTMLContent(ContainerContent)
class PdfContent(ContainerContent)
class BrowserContent(ContainerContent)

The SearchResult content class has a few extra fields:

class SearchResult(TextContent):
    url: str = ""
    title: str = ""
    snippet: str = ""
    engine: str = ""

You can pass instances of these content classes to any of the special functions, and most tool helpers will likely accept Content also.

If you see references to FunctionCallMeta in exceptions, it's because this classed is used to wrap the results of tool helper functions. You can extract the underlying value by calling the result() method on the object.

It is strongly recommended that you keep code blocks very short (1-5 lines of code or so) unless you're definining a new function. Remember, I'll be calling you multiple times with the results of those code blocks, so you'll have ample oppportunities to write more code. Think of this kind of like a Jupyter Notebook, where you're interleaving code and text and executing cell by cell.

## Task

The overall user task that the code is trying to solve:

{{task}}

## Code

Here is the possibly buggy python code. I'll show the problem, error, or exception after the code:

{{code}}

## Error

{{error}}

## State

I'll summarize the content/data of each of the variables that have been executed in the program so far. For brevity, I summarize and cut off long strings.

{{dictionary}}

Look at the code, look at the error, look at the summary of the variables that have been run so far and then re-write the entire python code to avoid the error. Do not explain yourself, don't ask questions, don't use natural language, just re-write the entire python code. Do not embed the code in ```python markdown blocks. Do not embed the code in <helpers></helpers> blocks. Just emit raw python code.

